
import cv2
import numpy as np
import streamlit as st
import os
from datetime import datetime
import queue
import time
import base64
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from main_pipeline import RunwayDetectionPipeline, VideoLogger
from session_utils import init_session_state

init_session_state()

# GerÃ§ek zamanlÄ± video iÅŸleme 
# RunwayDetectionPipeline ile ortak Ã§alÄ±ÅŸÄ±r
class StreamlitVideoProcessor:
    def __init__(self):
        self.processing = False
        self.frame_queue = queue.Queue(maxsize=10)
        self.status_queue = queue.Queue()
        self.current_frame = None
        self.stop_processing = False
        self.metrics = {
            'runway_detected': False,
            'segmentation_active': False,
            'deviation': 0,
            'confidence': 0.0,
            'mode': 'Searching...'
        }

    # Tek bir kareyi iÅŸler ve metrikleri gÃ¼nceller
    def process_frame_realtime(self, frame, pipeline):
        """Tek frame iÅŸleme - gerÃ§ek zamanlÄ± iÃ§in optimize edilmiÅŸ"""
        try:
            processed_frame = pipeline.process_frame(frame)
            
            # Metrics gÃ¼ncelle
            self.update_metrics_from_pipeline(pipeline)
            
            return processed_frame
            
        except Exception as e:
            st.error(f"Frame iÅŸleme hatasÄ±: {str(e)}")
            return frame
    
    # CanlÄ± video akÄ±ÅŸÄ± Ã¼zerinden kareleri iÅŸleyerek frame-by-frame Ã§Ä±ktÄ± verir
    def process_video_stream(self, video_path, yolo_model_path, unet_model_path, 
                           frame_callback=None, metrics_callback=None):
        """
        GerÃ§ek zamanlÄ± video stream iÅŸleme
        frame_callback: Her frame iÃ§in Ã§aÄŸrÄ±lacak fonksiyon
        metrics_callback: Metrics gÃ¼ncellemesi iÃ§in Ã§aÄŸrÄ±lacak fonksiyon
        """
        
        # Pipeline baÅŸlat
        pipeline = RunwayDetectionPipeline(yolo_model_path, unet_model_path)
        pipeline.logger.log_event("REALTIME_START", f"Real-time processing started: {video_path}")
        
        # Video input
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            raise Exception(f"Video aÃ§Ä±lamadÄ±: {video_path}")
        
        # Video properties
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        frame_count = 0
        self.processing = True
        self.stop_processing = False
        
        try:
            while self.processing and not self.stop_processing:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # Frame iÅŸle
                processed_frame = self.process_frame_realtime(frame, pipeline)
                
                # Callback'leri Ã§aÄŸÄ±r
                if frame_callback:
                    frame_callback(processed_frame, frame_count, total_frames)
                
                if metrics_callback:
                    metrics_callback(self.metrics)
                
                frame_count += 1
                
                # FPS kontrolÃ¼ (gerÃ§ek zamanlÄ± hissi iÃ§in)
                time.sleep(1.0 / fps if fps > 0 else 0.033)
                
        except Exception as e:
            pipeline.logger.log_event("ERROR", f"Stream processing error: {str(e)}")
            raise e
            
        finally:
            # Cleanup
            cap.release()
            self.processing = False
            
            # Log kaydet
            pipeline.logger.log_event("REALTIME_END", "Real-time processing completed")
            log_file = pipeline.logger.save_log()
            
            return {
                'log_file': log_file,
                'metrics': self.metrics,
                'total_frames': frame_count,
                'status': 'completed'
            }
        
    # Tam video iÅŸleme ve output_path'e video yazÄ±mÄ± yapar 
    def process_video_realtime(self, input_path, output_path, yolo_model_path, unet_model_path):
        """Eski stil video iÅŸleme - tam video iÅŸleme"""
        try:
            # Pipeline baÅŸlat
            pipeline = RunwayDetectionPipeline(yolo_model_path, unet_model_path)
            pipeline.logger.log_event("BATCH_START", f"Batch processing started: {input_path}")
            
            # Video input/output
            cap = cv2.VideoCapture(input_path)
            if not cap.isOpened():
                raise Exception(f"Video aÃ§Ä±lamadÄ±: {input_path}")
            
            # Video properties
            fps = int(cap.get(cv2.CAP_PROP_FPS))
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # Video writer
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            
            frame_count = 0
            processed_frames = 0
            
            # Progress bar oluÅŸtur
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # Frame iÅŸle
                processed_frame = self.process_frame_realtime(frame, pipeline)
                out.write(processed_frame)
                
                frame_count += 1
                processed_frames += 1
                
                # Progress gÃ¼ncelle
                progress = frame_count / total_frames if total_frames > 0 else 0
                progress_bar.progress(progress)
                status_text.text(f"Ä°ÅŸlenen frame: {frame_count}/{total_frames}")
                
                # Metrics gÃ¼ncelle
                self.update_metrics_from_pipeline(pipeline)
            
            # Cleanup
            cap.release()
            out.release()
            
            # Log kaydet
            pipeline.logger.log_event("BATCH_END", f"Batch processing completed. Frames: {processed_frames}")
            log_file = pipeline.logger.save_log()
            
            return output_path, log_file, self.metrics
            
        except Exception as e:
            if 'cap' in locals():
                cap.release()
            if 'out' in locals():
                out.release()
            raise e
        
    # Ä°ÅŸlemi manuel olarak durdurma 
    def stop_processing_stream(self):
        """Ä°ÅŸlemi durdur"""
        self.stop_processing = True
        self.processing = False
    
    # YOLO/U-Net Ã§Ä±ktÄ±larÄ±ndan Streamlit arayÃ¼zÃ¼nde gÃ¶sterilecek metirkler gÃ¼ncellenir 
    def update_metrics_from_pipeline(self, pipeline):
        """Pipeline'dan metrics gÃ¼ncelle"""
        self.metrics.update({
            'runway_detected': pipeline.runway_detected,
            'segmentation_active': pipeline.in_segmentation_mode,
            'confidence': getattr(pipeline, 'last_confidence', 0.0),
            'mode': 'Segmentasyon Aktif' if pipeline.in_segmentation_mode else 
                   ('Pist Tespit Edildi' if pipeline.runway_detected else 'Pist AranÄ±yor...')
        })
        
        # Deviation hesaplama
        if hasattr(pipeline, 'last_deviation'):
            self.metrics['deviation'] = pipeline.last_deviation

    # Ä°ÅŸlem durumu JSON benzeri dict olarak dÃ¶ner 
    def get_processing_status(self):
        """Mevcut iÅŸleme durumunu dÃ¶ndÃ¼r"""
        return {
            'processing': self.processing,
            'metrics': self.metrics.copy(),
            'stop_requested': self.stop_processing
        }
    
# Frame-by-frame iÅŸleyip anlÄ±k gÃ¶rsel ve metrik Ã§Ä±ktÄ±sÄ± Ã¼retir 
def process_video_realtime_streamlit(input_path, yolo_model_path, unet_model_path, 
                                   video_placeholder, metrics_placeholder, progress_bar):
    """
    Streamlit iÃ§in optimize edilmiÅŸ gerÃ§ek zamanlÄ± video iÅŸleme
    """
    processor = StreamlitVideoProcessor()
    
    def frame_callback(processed_frame, frame_count, total_frames):
        """Her frame iÃ§in Ã§aÄŸrÄ±lacak callback"""
        # Frame'i RGB'ye Ã§evir ve gÃ¶ster
        frame_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
        
        with video_placeholder.container():
            st.markdown('<div style="border: 2px solid #28a745; padding: 10px; border-radius: 10px;">', 
                       unsafe_allow_html=True)
            st.image(frame_rgb, channels="RGB", use_column_width=True)
            st.markdown(f"**ğŸ¬ Frame:** {frame_count}/{total_frames} | **âš¡ CanlÄ± Ä°ÅŸleme**")
            st.markdown('</div>', unsafe_allow_html=True)
        
        # Progress gÃ¼ncelle
        if total_frames > 0:
            progress = frame_count / total_frames
            progress_bar.progress(progress)
    
    def metrics_callback(metrics):
        """Metrics gÃ¼ncellemesi iÃ§in callback"""
        with metrics_placeholder.container():
            col1, col2 = st.columns(2)
            
            with col1:
                status = "âœ… Tespit Edildi" if metrics['runway_detected'] else "ğŸ” AranÄ±yor"
                color = "#28a745" if metrics['runway_detected'] else "#ffc107"
                st.markdown(f'<div style="background-color: {color}20; padding: 0.5rem; border-radius: 5px; border-left: 4px solid {color};">'
                           f'<strong>Pist:</strong> {status}</div>', unsafe_allow_html=True)
            
            with col2:
                seg_status = "ğŸ¯ Aktif" if metrics['segmentation_active'] else "â³ Bekliyor"
                seg_color = "#28a745" if metrics['segmentation_active'] else "#ffc107"
                st.markdown(f'<div style="background-color: {seg_color}20; padding: 0.5rem; border-radius: 5px; border-left: 4px solid {seg_color};">'
                           f'<strong>Segmentasyon:</strong> {seg_status}</div>', unsafe_allow_html=True)
            
            # GÃ¼ven skoru
            confidence = metrics.get('confidence', 0)
            conf_text = f"{confidence:.1%}" if confidence > 0 else "Bekleniyor"
            st.markdown(f'<div style="background-color: #f0f2f620; padding: 0.5rem; border-radius: 5px; border-left: 4px solid #2a5298;">'
                       f'<strong>GÃ¼ven Skoru:</strong> {conf_text}</div>', unsafe_allow_html=True)
            
            # Sapma deÄŸeri (varsa)
            if metrics.get('deviation', 0) != 0:
                deviation = metrics['deviation']
                dev_color = "#dc3545" if abs(deviation) > 50 else "#28a745"
                st.markdown(f'<div style="background-color: #f0f2f620; padding: 0.5rem; border-radius: 5px; border-left: 4px solid {dev_color};">'
                           f'<strong>Sapma:</strong> {deviation:.1f}Â°</div>', unsafe_allow_html=True)
    
    try:
        # Stream iÅŸleme baÅŸlat
        result = processor.process_video_stream(
            input_path, 
            yolo_model_path, 
            unet_model_path,
            frame_callback=frame_callback,
            metrics_callback=metrics_callback
        )
        
        return result
        
    except Exception as e:
        st.error(f"GerÃ§ek zamanlÄ± iÅŸleme hatasÄ±: {str(e)}")
        return {
            'error': str(e),
            'status': 'failed'
        }
    
# Arka plan iÅŸleme iÃ§in (geri uyumluluk), process_video_realtime Ã§aÄŸÄ±rÄ±r
def process_video(input_path, output_path, yolo_model_path, unet_model_path):
    """Mevcut process_video fonksiyonu - geriye dÃ¶nÃ¼k uyumluluk iÃ§in"""
    processor = StreamlitVideoProcessor()
    
    # Ä°ÅŸleme baÅŸlat
    with st.spinner('Video iÅŸleniyor... LÃ¼tfen bekleyin.'):
        try:
            # Eski stil iÅŸleme (tÃ¼m video iÅŸlendikten sonra sonuÃ§)
            output_file, log_file, final_metrics = processor.process_video_realtime(
                input_path, output_path, yolo_model_path, unet_model_path
            )
            
            return output_file, {
                'log_file': log_file,
                'metrics': final_metrics,
                'status': 'completed'
            }
            
        except Exception as e:
            st.error(f"Ä°ÅŸlem sÄ±rasÄ±nda hata oluÅŸtu: {str(e)}")
            return None, {
                'error': str(e),
                'status': 'failed'
            }
# Videoya veya log dosyalarÄ±nÄ± base64 formatÄ±nda indirilebilir hale getirir 
def create_download_link(file_path, link_text="Ä°ndir", file_name=None):
    """Dosya indirme linki oluÅŸtur"""
    if not os.path.exists(file_path):
        return None
    
    try:
        with open(file_path, "rb") as f:
            file_data = f.read()
        
        b64_data = base64.b64encode(file_data).decode()
        
        if file_name is None:
            file_name = os.path.basename(file_path)
        
        return f'<a href="data:application/octet-stream;base64,{b64_data}" download="{file_name}">{link_text}</a>'
    
    except Exception as e:
        st.error(f"Ä°ndirme linki oluÅŸturulamadÄ±: {str(e)}")
        return None

# Video dosyasÄ±nÄ±n Ã§Ã¶zÃ¼nÃ¼rlÃ¼k, FPS, sÃ¼re ve boyut bilgilerini alÄ±r 
def display_video_info(video_path):
    """Video bilgilerini gÃ¶ster"""
    try:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return None
        
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps if fps > 0 else 0
        
        cap.release()
        
        return {
            'fps': fps,
            'width': width,
            'height': height,
            'total_frames': total_frames,
            'duration': duration,
            'file_size': os.path.getsize(video_path) if os.path.exists(video_path) else 0
        }
    
    except Exception as e:
        st.error(f"Video bilgileri alÄ±namadÄ±: {str(e)}")
        return None

# YOLO ve U-net model yollarÄ±nÄ± ve uzantÄ±larÄ±nÄ± kontrol eder 
def validate_models(yolo_path, unet_path):
    """Model dosyalarÄ±nÄ± doÄŸrula"""
    errors = []
    
    if not os.path.exists(yolo_path):
        errors.append(f"YOLO model dosyasÄ± bulunamadÄ±: {yolo_path}")
    
    if not os.path.exists(unet_path):
        errors.append(f"U-Net model dosyasÄ± bulunamadÄ±: {unet_path}")
    
    # Dosya uzantÄ±larÄ±nÄ± kontrol et
    if yolo_path and not yolo_path.lower().endswith(('.pt', '.onnx', '.engine')):
        errors.append("YOLO model dosyasÄ± geÃ§ersiz format (.pt, .onnx, .engine desteklenir)")
    
    if unet_path and not unet_path.lower().endswith(('.pt', '.pth', '.onnx')):
        errors.append("U-Net model dosyasÄ± geÃ§ersiz format (.pt, .pth, .onnx desteklenir)")
    
    return errors

# Temp dosyalarÄ±nÄ± siler 
def cleanup_temp_files(file_paths):
    """GeÃ§ici dosyalarÄ± temizle"""
    cleaned_files = []
    
    for file_path in file_paths:
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                cleaned_files.append(file_path)
        except Exception as e:
            st.warning(f"GeÃ§ici dosya silinemedi {file_path}: {str(e)}")
    
    return cleaned_files

# Byte tÃ¼rÃ¼nden dosya boyutunu okunabilir birimlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
def format_file_size(size_bytes):
    """Dosya boyutunu okunabilir formata Ã§evir"""
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB"]
    import math
    i = int(math.floor(math.log(size_bytes, 1024)))
    p = math.pow(1024, i)
    s = round(size_bytes / p, 2)
    
    return f"{s} {size_names[i]}"

# Saniyeyi saat, dakika, saniye formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
def format_duration(seconds):
    """SÃ¼reyi okunabilir formata Ã§evir"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    
    if hours > 0:
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"
    else:
        return f"{minutes:02d}:{secs:02d}"

"""
# st.session_state iÃ§indeki gerekli anahtarlarÄ± ilk defa baÅŸlatÄ±r 
def init_session_state():
    #Session state'i baÅŸlat
    if 'processing' not in st.session_state:
        st.session_state.processing = False
    
    if 'last_result' not in st.session_state:
        st.session_state.last_result = None
    
    if 'processor' not in st.session_state:
        st.session_state.processor = None
"""

# iÅŸlem durduÄŸunda veya yeniden baÅŸlatÄ±ldÄ±ÄŸÄ±nda session_state'i temizler 
def reset_session_state():
    """Session state'i sÄ±fÄ±rla"""
    st.session_state.processing = False
    st.session_state.last_result = None
    if st.session_state.processor:
        st.session_state.processor.stop_processing_stream()
    st.session_state.processor = None